{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"KladML","text":"<p>Universal MLOps: Zero to Training in 60 Seconds</p>"},{"location":"#what-is-kladml","title":"What is KladML?","text":"<p>KladML is a modular SDK for building production-ready machine learning pipelines. Unlike heavy MLOps frameworks, KladML gives you:</p> <ul> <li>Universal Quickstart - Auto-detect data type, suggest pipeline, train in one command</li> <li>Interface-based architecture - Swap backends without changing code</li> <li>Local-first - No servers required, works offline with SQLite</li> <li>High Performance - Powered by Polars (Data) and Torch Compile (Models)</li> <li>Extensible - Register custom architectures, preprocessors, and evaluators</li> <li>CLI included - Initialize projects, run experiments from terminal</li> </ul>"},{"location":"#quick-install","title":"Quick Install","text":"<pre><code># Core library\npip install kladml\n\n# Full CLI with TUI\npip install \"kladml[cli]\"\n</code></pre>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#zero-to-training-in-60-seconds","title":"Zero to Training in 60 Seconds","text":"<pre><code>kladml quickstart --data my_data.csv\n\n# Output:\n# \ud83d\udcca Analyzing data...\n#    Data type: TABULAR (5 columns, 1000 rows)\n#\n# ? What task do you want to perform?\n#   &gt; Classification (detected 'label' column)\n#\n# \ud83d\udd27 Selected: XGBoostClassifier + ClassificationEvaluator\n# \ud83d\ude80 Training...\n# \u2705 Complete! Results saved to data/projects/quickstart/run_001/\n</code></pre>"},{"location":"#supported-data-types","title":"Supported Data Types","text":"Data Type Auto-Detection Default Pipeline TABULAR Numeric CSV/Parquet XGBoost  (Coming Soon) TIMESERIES Has datetime column Transformer IMAGE Folder with JPG/PNG ResNet50 TEXT CSV with text columns BERT (Coming Soon)"},{"location":"#why-kladml","title":"Why KladML?","text":"Feature KladML MLflow ClearML Interface-based \u2705 Pluggable \u274c Hardcoded \u274c Hardcoded Server required \u274c No \u26a0\ufe0f Optional \u2705 Yes Local-first \u2705 SQLite default \u2705 Yes \u274c No Data Engine \ud83d\ude80 Polars \ud83d\udc22 Pandas \ud83d\udc22 Pandas Learning curve \ud83d\udfe2 Minutes \ud83d\udfe1 Days \ud83d\udd34 Weeks Universal Quickstart \u2705 Yes \u274c No \u274c No"},{"location":"#documentation","title":"Documentation","text":"<ul> <li>\ud83d\ude80 Getting Started \u2014 Install, configure, and run your first experiment</li> <li>\ud83e\udde0 Core Concepts \u2014 Understand interfaces, runners, and the architecture</li> <li>\ud83c\udfd7\ufe0f Model Architecture \u2014 Deep dive into model contracts and design patterns</li> <li>\ud83d\uddfa\ufe0f Roadmap \u2014 Planned features and what's coming next</li> <li>\ud83d\udce6 CLI Reference \u2014 All available commands and options</li> <li>\ud83d\udea2 Deployment \u2014 Export and deploy to edge devices</li> </ul>"},{"location":"#links","title":"Links","text":"<ul> <li>GitHub Repository</li> <li>PyPI Package</li> <li>Report Issues</li> </ul>"},{"location":"architecture/","title":"Model Architecture","text":"<p>KladML provides standardized base classes that ensure your models are portable, reproducible, and easy to track.</p>"},{"location":"architecture/#basemodel","title":"BaseModel","text":"<p>The core abstract class that all models inherit from.</p> <pre><code>from kladml import BaseModel\n\nclass BaseModel(ABC):\n    \"\"\"Base class for all ML models.\"\"\"\n\n    @abstractmethod\n    def train(self, X_train, y_train=None, X_val=None, y_val=None, **kwargs) -&gt; Dict[str, Any]:\n        \"\"\"Train the model. Must return a metrics dictionary.\"\"\"\n        pass\n\n    @abstractmethod\n    def predict(self, X, **kwargs) -&gt; Any:\n        \"\"\"Generate predictions.\"\"\"\n        pass\n\n    @abstractmethod\n    def evaluate(self, X_test, y_test=None, **kwargs) -&gt; Dict[str, float]:\n        \"\"\"Evaluate the model. Must return a metrics dictionary.\"\"\"\n        pass\n\n    @abstractmethod\n    def save(self, path: str) -&gt; None:\n        \"\"\"Save model artifacts to directory.\"\"\"\n        pass\n\n    @abstractmethod\n    def load(self, path: str) -&gt; None:\n        \"\"\"Load model artifacts from directory.\"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def ml_task(self) -&gt; MLTask:\n        \"\"\"Return the ML task type.\"\"\"\n        pass\n</code></pre>"},{"location":"architecture/#specialized-model-classes","title":"Specialized Model Classes","text":"<p>KladML provides pre-configured subclasses for common ML tasks:</p>"},{"location":"architecture/#timeseriesmodel","title":"TimeSeriesModel","text":"<p>For forecasting and time-series analysis.</p> <pre><code>from kladml import TimeSeriesModel, MLTask\n\nclass MyForecaster(TimeSeriesModel):\n\n    @property\n    def ml_task(self):\n        return MLTask.TIMESERIES_FORECASTING\n\n    def train(self, X_train, y_train=None, **kwargs):\n        # Train on sequences\n        return {\"loss\": 0.1}\n\n    def predict(self, X, **kwargs):\n        # Forecast future values\n        return predictions\n\n    # ... implement other methods\n</code></pre>"},{"location":"architecture/#classificationmodel","title":"ClassificationModel","text":"<p>For classification tasks.</p> <pre><code>from kladml import ClassificationModel, MLTask\n\nclass MyClassifier(ClassificationModel):\n\n    @property\n    def ml_task(self):\n        return MLTask.CLASSIFICATION\n\n    def train(self, X_train, y_train=None, **kwargs):\n        return {\"accuracy\": 0.95, \"f1\": 0.92}\n\n    def predict(self, X, **kwargs):\n        return class_labels\n</code></pre>"},{"location":"architecture/#mltask-enum","title":"MLTask Enum","text":"<p>Defines the problem type your model solves. This helps the framework visualize and evaluate results correctly.</p> <pre><code>from kladml import MLTask\n\nclass MLTask(Enum):\n    REGRESSION = \"regression\"\n    CLASSIFICATION = \"classification\"\n    TIMESERIES_FORECASTING = \"timeseries_forecasting\"\n    CLUSTERING = \"clustering\"\n    ANOMALY_DETECTION = \"anomaly_detection\"\n</code></pre>"},{"location":"architecture/#method-contracts","title":"Method Contracts","text":""},{"location":"architecture/#train","title":"<code>train()</code>","text":"<p>Input: - <code>X_train</code>: Training features - <code>y_train</code>: Training labels (optional for unsupervised) - <code>X_val</code>, <code>y_val</code>: Validation data (optional) - <code>**kwargs</code>: Additional parameters</p> <p>Output: - <code>Dict[str, Any]</code>: Metrics dictionary (e.g., <code>{\"loss\": 0.1, \"epochs\": 10}</code>)</p> <p>Side effects: - Sets <code>self._is_trained = True</code> - Model state is updated</p>"},{"location":"architecture/#predict","title":"<code>predict()</code>","text":"<p>Input: - <code>X</code>: Features to predict on - <code>**kwargs</code>: Additional parameters</p> <p>Output: - Predictions (numpy array, list, tensor, etc.)</p> <p>Precondition: - Model must be trained (<code>self._is_trained == True</code>)</p>"},{"location":"architecture/#evaluate","title":"<code>evaluate()</code>","text":"<p>Input: - <code>X_test</code>: Test features - <code>y_test</code>: Test labels (optional) - <code>**kwargs</code>: Additional parameters</p> <p>Output: - <code>Dict[str, float]</code>: Metrics dictionary (e.g., <code>{\"mae\": 0.5, \"rmse\": 0.7}</code>)</p>"},{"location":"architecture/#save-load","title":"<code>save()</code> / <code>load()</code>","text":"<p>Input: - <code>path: str</code>: Directory path for saving/loading</p> <p>Behavior: - Save all model artifacts (weights, config, metadata) to the directory - Load should restore the model to trainable/predictable state</p> <p>Example:</p> <pre><code>def save(self, path: str):\n    import json\n    import numpy as np\n\n    # Save weights\n    np.save(f\"{path}/weights.npy\", self.weights)\n\n    # Save config\n    with open(f\"{path}/config.json\", \"w\") as f:\n        json.dump({\"hidden_size\": 64}, f)\n\ndef load(self, path: str):\n    import json\n    import numpy as np\n\n    self.weights = np.load(f\"{path}/weights.npy\")\n    with open(f\"{path}/config.json\") as f:\n        self.config = json.load(f)\n\n    self._is_trained = True\n</code></pre>"},{"location":"architecture/#design-philosophy","title":"Design Philosophy","text":"<ol> <li>Pure Python interfaces - No heavy framework dependencies in the contract</li> <li>Separation of concerns - Models handle math, <code>ExperimentRunner</code> handles infrastructure</li> <li>Portability - Same model code runs locally, in Docker, or on Kubernetes</li> <li>Testability - Easy to unit test each method independently</li> </ol>"},{"location":"cli/","title":"CLI Reference","text":"<p>KladML includes a command-line interface for common tasks.</p>"},{"location":"cli/#hierarchy-overview","title":"Hierarchy Overview","text":"<p>KladML organizes work in a 4-level hierarchy:</p> <pre><code>Workspace &gt; Projects &gt; Family &gt; Experiment &gt; Run\n</code></pre> <ul> <li>Project: Top-level container (e.g., <code>sentinella</code>)</li> <li>Family: Groups related experiments (e.g., <code>glucose_forecasting</code>)</li> <li>Experiment: A specific model/approach (e.g., <code>gluformer_v4</code>)</li> <li>Run: Single training execution with specific params</li> </ul>"},{"location":"cli/#global-commands","title":"Global Commands","text":""},{"location":"cli/#kladml-ui","title":"<code>kladml ui</code>","text":"<p>Launch the interactive Terminal User Interface (TUI). This provides a visual workspace to explore: - Projects, Families, and Experiments (Tree View) - Datasets (List and details) - Configs (File viewer) - Run Details (Parameters and Metrics)</p> <pre><code>kladml ui\n</code></pre>"},{"location":"cli/#kladml-version","title":"<code>kladml version</code>","text":"<p>Show the installed version.</p> <pre><code>kladml version\n</code></pre>"},{"location":"cli/#kladml-help","title":"<code>kladml --help</code>","text":"<p>Show all available commands.</p>"},{"location":"cli/#project-commands","title":"Project Commands","text":""},{"location":"cli/#kladml-project-create","title":"<code>kladml project create</code>","text":"<p>Create a new project.</p> <pre><code>kladml project create &lt;name&gt; [--description TEXT]\n</code></pre>"},{"location":"cli/#kladml-project-list","title":"<code>kladml project list</code>","text":"<p>List all projects.</p> <pre><code>kladml project list\n</code></pre>"},{"location":"cli/#kladml-project-show","title":"<code>kladml project show</code>","text":"<p>Show project details.</p> <pre><code>kladml project show &lt;name&gt;\n</code></pre>"},{"location":"cli/#kladml-project-delete","title":"<code>kladml project delete</code>","text":"<p>Delete a project.</p> <pre><code>kladml project delete &lt;name&gt; [--force]\n</code></pre>"},{"location":"cli/#family-commands","title":"Family Commands","text":"<p>Families group related experiments within a project.</p>"},{"location":"cli/#kladml-family-create","title":"<code>kladml family create</code>","text":"<p>Create a new family under a project.</p> <pre><code>kladml family create -p &lt;project&gt; -n &lt;name&gt; [-d DESCRIPTION]\n</code></pre> <p>Example:</p> <pre><code>kladml family create -p sentinella -n glucose_forecasting -d \"Blood glucose prediction models\"\n</code></pre>"},{"location":"cli/#kladml-family-list","title":"<code>kladml family list</code>","text":"<p>List families in a project.</p> <pre><code>kladml family list -p &lt;project&gt;\n</code></pre>"},{"location":"cli/#kladml-family-delete","title":"<code>kladml family delete</code>","text":"<p>Delete a family.</p> <pre><code>kladml family delete &lt;name&gt; -p &lt;project&gt; [--force]\n</code></pre>"},{"location":"cli/#experiment-commands","title":"Experiment Commands","text":""},{"location":"cli/#kladml-experiment-create","title":"<code>kladml experiment create</code>","text":"<p>Create a new experiment under a family.</p> <pre><code>kladml experiment create -p &lt;project&gt; -f &lt;family&gt; -n &lt;name&gt;\n</code></pre> <p>Example:</p> <pre><code>kladml experiment create -p sentinella -f glucose_forecasting -n gluformer_v4\n</code></pre>"},{"location":"cli/#kladml-experiment-list","title":"<code>kladml experiment list</code>","text":"<p>List experiments (grouped by family).</p> <pre><code>kladml experiment list -p &lt;project&gt; [-f &lt;family&gt;]\n</code></pre>"},{"location":"cli/#kladml-experiment-runs","title":"<code>kladml experiment runs</code>","text":"<p>List runs in an experiment.</p> <pre><code>kladml experiment runs &lt;experiment-name&gt; [--max N]\n</code></pre>"},{"location":"cli/#run-commands","title":"Run Commands","text":""},{"location":"cli/#kladml-run-native","title":"<code>kladml run native</code>","text":"<p>Run a training script using your local Python environment.</p> <pre><code>kladml run native &lt;script&gt; [OPTIONS]\n</code></pre> <p>Options:</p> Option Default Description <code>--experiment</code>, <code>-e</code> <code>default</code> Experiment name for tracking <p>Example:</p> <pre><code>kladml run native train.py --experiment baseline\n</code></pre>"},{"location":"cli/#kladml-run-local","title":"<code>kladml run local</code>","text":"<p>Run a training script inside a Docker/Podman container.</p> <pre><code>kladml run local &lt;script&gt; [OPTIONS]\n</code></pre> <p>Arguments:</p> Argument Description <code>script</code> Path to the Python script to run <p>Options:</p> Option Default Description <code>--experiment</code>, <code>-e</code> <code>default</code> Experiment name for tracking <p>Example:</p> <pre><code>kladml run native train.py --experiment baseline\n</code></pre>"},{"location":"cli/#training-commands","title":"Training Commands","text":""},{"location":"cli/#kladml-train-quick","title":"<code>kladml train quick</code>","text":"<p>Recommended - Quick training without database setup.</p> <pre><code>kladml train quick [OPTIONS]\n</code></pre> <p>Options:</p> Option Required Description <code>--config</code>, <code>-c</code> Yes Path to YAML config file <code>--train</code>, <code>-t</code> Yes Path to training data (<code>.pkl</code> or <code>.h5</code>) <code>--val</code>, <code>-v</code> No Path to validation data <code>--model</code>, <code>-m</code> No Model name (default: <code>gluformer</code>) <code>--device</code>, <code>-d</code> No Device: <code>auto</code>, <code>cpu</code>, <code>cuda</code>, <code>mps</code> <code>--resume</code>, <code>-r</code> No Resume from latest checkpoint <p>Examples:</p> <pre><code># Basic training\nkladml train quick -c data/configs/my_config.yaml -t train.pkl -v val.pkl\n\n# Resume interrupted training\nkladml train quick -c data/configs/my_config.yaml -t train.pkl --resume\n</code></pre>"},{"location":"cli/#kladml-train-single","title":"<code>kladml train single</code>","text":"<p>Full training with project and experiment tracking (requires database setup).</p> <pre><code>kladml train single [OPTIONS]\n</code></pre> <p>Options:</p> Option Required Description <code>--model</code>, <code>-m</code> Yes Model architecture name (e.g., <code>gluformer</code>) <code>--data</code>, <code>-d</code> Yes Path to training data <code>--val</code> No Path to validation data <code>--project</code>, <code>-p</code> Yes Project name <code>--family</code>, <code>-f</code> No Family name (default: <code>default</code>) <code>--experiment</code>, <code>-e</code> Yes Experiment name <code>--config</code>, <code>-c</code> No Path to YAML config file <p>Example:</p> <pre><code>kladml train single --model gluformer --data train.h5 --project sentinella --experiment v1\n</code></pre>"},{"location":"cli/#kladml-train-grid","title":"<code>kladml train grid</code>","text":"<p>Run a grid search over hyperparameters.</p> <pre><code>kladml train grid [OPTIONS]\n</code></pre> <p>The configuration file must define lists of values for grid search.</p> <p>Example:</p> <pre><code>kladml train grid --model gluformer --config grid.yaml --project sentinella --experiment tuning\n</code></pre>"},{"location":"cli/#evaluation-commands","title":"Evaluation Commands","text":""},{"location":"cli/#kladml-eval-run","title":"<code>kladml eval run</code>","text":"<p>Evaluate a trained model on test data.</p> <pre><code>kladml eval run [OPTIONS]\n</code></pre> <p>Options:</p> Option Required Description <code>--checkpoint</code> Yes Path to model checkpoint (<code>.pt</code> file) <code>--data</code> Yes Path to test data <code>--model</code> No Model type (default: auto-detect) <code>--output</code> No Output directory for results <code>--device</code> No Device: <code>auto</code>, <code>cpu</code>, <code>cuda</code> <p>Example:</p> <pre><code>kladml eval run --checkpoint best_model_jit.pt --data test.pkl --output eval_results/\n</code></pre> <p>Output includes: - Metrics (MAE, RMSE, MAPE, Coverage) - Plots (predictions, error distribution, scatter) - JSON metrics file and markdown report</p>"},{"location":"cli/#kladml-eval-info","title":"<code>kladml eval info</code>","text":"<p>Show available evaluators for each model type.</p> <pre><code>kladml eval info\n</code></pre>"},{"location":"cli/#data-commands","title":"Data Commands","text":""},{"location":"cli/#kladml-data-inspect","title":"<code>kladml data inspect</code>","text":"<p>Analyze a <code>.pkl</code> dataset file.</p> <pre><code>kladml data inspect &lt;path&gt;\n</code></pre>"},{"location":"cli/#kladml-data-convert","title":"<code>kladml data convert</code>","text":"<p>Convert a dataset to efficient formats (Parquet, HDF5).</p> <pre><code>kladml data convert [OPTIONS]\n</code></pre> <p>Options:</p> Option Required Description <code>--input</code>, <code>-i</code> Yes Input <code>.pkl</code> file path <code>--output</code>, <code>-o</code> Yes Output file path (<code>.parquet</code> or <code>.h5</code>) <code>--format</code>, <code>-f</code> No Format: <code>parquet</code>, <code>hdf5</code> (default: <code>hdf5</code>) <code>--compression</code> No Compression (gzip, zstd). Default: gzip/zstd <p>Example:</p> <pre><code>kladml data convert -i train.pkl -o train.parquet --format parquet\n</code></pre>"},{"location":"cli/#configuration-management","title":"Configuration Management","text":""},{"location":"cli/#kladml-config-create","title":"<code>kladml config create</code>","text":"<p>Generate a 'smart' configuration file for a model using dataset heuristics.</p> <pre><code>kladml config create [OPTIONS]\n</code></pre> <p>Options:</p> Option Required Description <code>--model</code>, <code>-m</code> Yes Model name (e.g. <code>gluformer</code>) <code>--data</code>, <code>-d</code> No Path to training data for auto-tuning <code>--output</code>, <code>-o</code> No Output path (default: <code>config.yaml</code>) <p>Example:</p> <pre><code># Generate config tailored to your dataset\nkladml config create --model gluformer --data data/train.parquet\n</code></pre>"},{"location":"cli/#environment-variables","title":"Environment Variables","text":"<p>KladML respects these environment variables:</p> Variable Description <code>KLADML_TRAINING_DEVICE</code> Override default device (<code>cpu</code>, <code>cuda</code>, <code>mps</code>) <code>KLADML_STORAGE_ARTIFACTS_DIR</code> Directory for saving artifacts <code>KLADML_EXPERIMENT</code> Default experiment name"},{"location":"cli/#hyperparameter-tuning","title":"Hyperparameter Tuning","text":""},{"location":"cli/#kladml-tune","title":"<code>kladml tune</code>","text":"<p>Run automated hyperparameter tuning using Optuna.</p> <pre><code>kladml tune [OPTIONS]\n</code></pre> <p>Options:</p> Option Required Description <code>--config</code>, <code>-c</code> Yes Path to YAML config file <code>--n-trials</code>, <code>-n</code> No Number of trials (default: 50) <code>--timeout</code> No Maximum tuning time in seconds <code>--pruner</code> No Pruning strategy: <code>median</code>, <code>hyperband</code> (default: <code>median</code>) <code>--study-name</code> No Name for the Optuna study <code>--storage</code> No Database URL for distributed tuning <p>Examples:</p> <pre><code># Basic tuning\nkladml tune --config config.yaml --n-trials 50\n\n# With timeout\nkladml tune --config config.yaml --n-trials 100 --timeout 3600\n\n# Distributed tuning with shared database\nkladml tune --config config.yaml --storage sqlite:///optuna.db --study-name my-study\n</code></pre> <p>Output: - Best configuration saved to <code>best_config.yaml</code> - Optimization history plot - Parameter importance plot</p>"},{"location":"cli/#run-comparison","title":"Run Comparison","text":""},{"location":"cli/#kladml-compare","title":"<code>kladml compare</code>","text":"<p>Compare multiple training runs visually.</p> <pre><code>kladml compare --runs &lt;run_ids&gt; [OPTIONS]\n</code></pre> <p>Options:</p> Option Required Description <code>--runs</code>, <code>-r</code> Yes Comma-separated list of run IDs <code>--metric</code>, <code>-m</code> No Metric to compare (default: <code>val_loss</code>) <code>--output</code>, <code>-o</code> No Output directory for comparison plots <p>Examples:</p> <pre><code># Compare two runs\nkladml compare --runs run_001,run_002 --metric val_loss\n\n# Compare multiple runs\nkladml compare --runs run_001,run_002,run_003 --metric accuracy --output comparisons/\n</code></pre> <p>Output: - Tabular comparison of Metrics (all logged metrics) - Tabular comparison of Parameters (hyperparameters, config) - Side-by-side view for direct analysis</p>"},{"location":"cli/#component-registration","title":"Component Registration","text":""},{"location":"cli/#kladml-registry-add","title":"<code>kladml registry add</code>","text":"<p>Register custom components (architectures, preprocessors, evaluators).</p> <pre><code>kladml registry add [OPTIONS]\n</code></pre> <p>Component Types:</p> Type Description <code>model</code> Custom model architecture <code>preprocessor</code> Custom data preprocessor <code>evaluator</code> Custom evaluator <p>Options:</p> Option Required Description <code>--name</code>, <code>-n</code> Yes Name for the component <code>--path</code>, <code>-p</code> Yes Path to artifact file/dir <code>--type</code>, <code>-t</code> Yes Type (model, preprocessor, etc.) <code>--tag</code> No Tags to attach <p>Examples:</p> <pre><code># Register a custom architecture\nkladml registry add --name MyTransformer --path src/models/my_transformer.py --type model --tag experimental\n\n# Register a custom preprocessor\nkladml registry add --name MyScaler --path src/data/scaler.pkl --type preprocessor\n</code></pre>"},{"location":"cli/#kladml-registry-list","title":"<code>kladml registry list</code>","text":"<p>List registered artifacts.</p> <pre><code>kladml registry list [OPTIONS]\n</code></pre> <p>Examples:</p> <pre><code>kladml registry list --type model\nkladml registry list --tag production\n</code></pre>"},{"location":"cli/#kladml-registry-show","title":"<code>kladml registry show</code>","text":"<p>Show details of a registered artifact.</p> <pre><code>kladml registry show &lt;name&gt;\n</code></pre>"},{"location":"core_concepts/","title":"Core Concepts","text":"<p>KladML is built on a \"1 Interface, N Implementations\" philosophy. This allows you to run the same code locally (with files and SQLite) and in production (with S3, databases, etc.) without changing your logic.</p>"},{"location":"core_concepts/#architecture-overview","title":"Architecture Overview","text":"<p>KladML organizes your work in a structured hierarchy, starting from a Workspace:</p> <pre><code>Workspace\n\u251c\u2500\u2500 Projects (Logic)\n\u2502   \u2514\u2500\u2500 Family\n\u2502       \u2514\u2500\u2500 Experiment\n\u2502           \u2514\u2500\u2500 Run\n\u251c\u2500\u2500 Datasets (Data versioning)\n\u2514\u2500\u2500 Configs (Configuration files)\n</code></pre> <ul> <li>Workspace: Root of your local environment (<code>data/</code>).</li> <li>Project: High-level container (e.g., \"CustomerChurn\").</li> <li>Family: Grouping of related experiments (e.g., \"glucose_forecasting\").</li> <li>Dataset: First-class entity, synced to DB.</li> <li>Run: Individual training execution.</li> </ul>"},{"location":"core_concepts/#component-architecture","title":"Component Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      Your Code                              \u2502\n\u2502         (Model implementation, Training script)             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                   ExperimentRunner                          \u2502\n\u2502         (Orchestrates training, tracking, storage)          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  StorageInterface  \u2502  ConfigInterface  \u2502  TrackerInterface  \u2502\n\u2502                    \u2502                   \u2502                    \u2502\n\u2502  (Abstraction)     \u2502  (Abstraction)    \u2502  (Abstraction)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  LocalStorage      \u2502  YamlConfig       \u2502  LocalTracker      \u2502\n\u2502  S3Storage         \u2502  EnvConfig        \u2502  MLflowTracker     \u2502\n\u2502  (Implementation)  \u2502  (Implementation) \u2502  (Implementation)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"core_concepts/#interfaces","title":"Interfaces","text":"<p>KladML defines 4 core interfaces. Each interface defines what a backend must do, not how.</p>"},{"location":"core_concepts/#storageinterface","title":"StorageInterface","text":"<p>Handles files and artifacts (models, data, outputs).</p> <pre><code>from kladml.interfaces import StorageInterface\n\nclass StorageInterface(ABC):\n    @abstractmethod\n    def upload_file(self, local_path: str, bucket: str, key: str) -&gt; str: ...\n\n    @abstractmethod\n    def download_file(self, bucket: str, key: str, local_path: str) -&gt; str: ...\n\n    @abstractmethod\n    def list_files(self, bucket: str, prefix: str = \"\") -&gt; List[str]: ...\n</code></pre> <p>Default: <code>LocalStorage</code> (filesystem)</p>"},{"location":"core_concepts/#configinterface","title":"ConfigInterface","text":"<p>Manages configuration and settings.</p> <pre><code>from kladml.interfaces import ConfigInterface\n\nclass ConfigInterface(ABC):\n    @abstractmethod\n    def get(self, key: str, default: Any = None) -&gt; Any: ...\n\n    @abstractmethod\n    def set(self, key: str, value: Any) -&gt; None: ...\n</code></pre> <p>Default: <code>YamlConfig</code> (reads from <code>kladml.yaml</code> + environment variables)</p>"},{"location":"core_concepts/#trackerinterface","title":"TrackerInterface","text":"<p>Logs experiments, parameters, and metrics.</p> <pre><code>from kladml.interfaces import TrackerInterface\n\nclass TrackerInterface(ABC):\n    @abstractmethod\n    def start_run(self, experiment_name: str, run_name: str = None) -&gt; str: ...\n\n    @abstractmethod\n    def log_params(self, params: Dict[str, Any]) -&gt; None: ...\n\n    @abstractmethod\n    def log_metric(self, key: str, value: float, step: int = None) -&gt; None: ...\n\n    @abstractmethod\n    def end_run(self, status: str = \"FINISHED\") -&gt; None: ...\n</code></pre> <p>Default: <code>LocalTracker</code> (MLflow + SQLite)</p>"},{"location":"core_concepts/#publisherinterface","title":"PublisherInterface","text":"<p>Publishes real-time updates during training.</p> <pre><code>from kladml.interfaces import PublisherInterface\n\nclass PublisherInterface(ABC):\n    @abstractmethod\n    def publish(self, channel: str, message: Dict[str, Any]) -&gt; None: ...\n</code></pre> <p>Default: <code>ConsolePublisher</code> (prints to stdout)</p>"},{"location":"core_concepts/#the-experimentrunner","title":"The ExperimentRunner","text":"<p>The <code>ExperimentRunner</code> is the central orchestrator. It:</p> <ol> <li>Loads configuration from <code>kladml.yaml</code></li> <li>Starts a tracking run (MLflow)</li> <li>Instantiates your model</li> <li>Calls <code>train()</code> and logs metrics</li> <li>Calls <code>evaluate()</code> and logs results</li> <li>Saves artifacts (model weights, config)</li> </ol> <pre><code>from kladml import ExperimentRunner\n\nrunner = ExperimentRunner(\n    storage=LocalStorage(),      # Optional: custom storage\n    config=YamlConfig(),         # Optional: custom config\n    tracker=LocalTracker(),      # Optional: custom tracker\n)\n\nresult = runner.run(\n    model_class=MyModel,\n    train_data=(X_train, y_train),\n    experiment_name=\"my-experiment\",\n)\n</code></pre>"},{"location":"core_concepts/#implementing-custom-backends","title":"Implementing Custom Backends","text":"<p>Want to use S3 instead of local files? Implement the interface:</p> <pre><code>from kladml.interfaces import StorageInterface\nimport boto3\n\nclass S3Storage(StorageInterface):\n    def __init__(self, bucket_name: str):\n        self.s3 = boto3.client('s3')\n        self.bucket = bucket_name\n\n    def upload_file(self, local_path: str, bucket: str, key: str) -&gt; str:\n        self.s3.upload_file(local_path, bucket, key)\n        return f\"s3://{bucket}/{key}\"\n\n    def download_file(self, bucket: str, key: str, local_path: str) -&gt; str:\n        self.s3.download_file(bucket, key, local_path)\n        return local_path\n\n    def list_files(self, bucket: str, prefix: str = \"\") -&gt; List[str]:\n        response = self.s3.list_objects_v2(Bucket=bucket, Prefix=prefix)\n        return [obj['Key'] for obj in response.get('Contents', [])]\n\n# Use it\nrunner = ExperimentRunner(storage=S3Storage(\"my-bucket\"))\n</code></pre>"},{"location":"core_concepts/#advanced-usage","title":"Advanced Usage","text":""},{"location":"core_concepts/#lightweight-installation","title":"Lightweight Installation","text":"<p>If you are running KladML in a lightweight environment (e.g. CI/CD, Scripts, Notebooks) where you don't need the TUI:</p> <ul> <li>Core (<code>pip install kladml</code>): Installs only essential ML logic and models.</li> <li>Full CLI (<code>pip install \"kladml[cli]\"</code>): Includes the TUI and rich terminal formatting.</li> </ul>"},{"location":"core_concepts/#modular-design","title":"Modular Design","text":"<p>KladML uses a modular interface-based design. This ensures your training code is decoupled from the underlying storage or tracking implementation, keeping your codebase clean and testable.</p>"},{"location":"core_concepts/#next-steps","title":"Next Steps","text":"<ul> <li>Architecture - Model contracts and design patterns</li> <li>CLI Reference - Command-line interface</li> <li>Roadmap - Planned features</li> </ul>"},{"location":"core_concepts/#training-architecture","title":"Training Architecture","text":"<p>Starting from v0.9.0, KladML uses a Universal Trainer powered by Hugging Face Accelerate.</p>"},{"location":"core_concepts/#key-features","title":"Key Features","text":"<ol> <li> <p>Backend Agnostic: The exact same code runs on:</p> <ul> <li>CPU (Standard)</li> <li>GPU (CUDA for NVIDIA, MPS for Apple Silicon)</li> <li>Multi-GPU (DDP via <code>distributed</code> flag)</li> <li>TPU (Google Cloud)</li> </ul> </li> <li> <p>Capabilities:</p> <ul> <li>Mixed Precision: Native support for <code>fp16</code> (halves memory usage) and <code>bf16</code> (better stability).</li> <li>Gradient Accumulation: Simulate large batch sizes on small hardware.</li> <li>Gradient Clipping: Stabilize training automatically.</li> </ul> </li> <li> <p>Lifecycle Management:</p> <ul> <li>Checkpoints: Automatic saving of <code>best_model</code> and periodic states.</li> <li>Early Stopping: Configurable patience and delta.</li> <li>Tracking: Seamless integration with MLflow (or custom trackers) via <code>TrackerInterface</code>.</li> </ul> </li> </ol>"},{"location":"core_concepts/#configuration","title":"Configuration","text":"<p>Everything is controlled via <code>TrainingConfig</code>:</p> <pre><code>training:\n  max_epochs: 100\n  batch_size: 64\n  mixed_precision: \"fp16\"       # no | fp16 | bf16\n  gradient_accumulation_steps: 4\n  gradient_clipping: 1.0\n\n  early_stopping:\n    enabled: true\n    patience: 10\n</code></pre>"},{"location":"deployment/","title":"Deployment","text":"<p>KladML provides robust tools for deploying your trained models to various environments, with a primary focus on Edge and Embedded devices via TorchScript optimization.</p>"},{"location":"deployment/#automatic-export","title":"Automatic Export","text":"<p>Starting from v0.3.0, every training run automatically generates a deployment-optimized artifact alongside the standard checkpoint.</p> <p>When <code>train()</code> completes (or finds a best model), it creates: - <code>checkpoints/best_model.pth</code>: Python-dependent PyTorch checkpoint (contains weights + optimizer state). Use for resuming training or fine-tuning. - <code>checkpoints/best_model_jit.pt</code>: Deployment Artifact. A standalone TorchScript file containing the model architecture, weights, and embedded scaler statistics.</p>"},{"location":"deployment/#manual-export","title":"Manual Export","text":"<p>You can export any existing checkpoint using the CLI:</p> <pre><code>kladml export \\\n    --checkpoint ./data/projects/my_project/experiments/exp1/run_id/checkpoints/best_model.pth \\\n    --output ./deployment/model.pt \\\n    --config ./data/projects/my_project/experiments/exp1/run_id/config.yaml\n</code></pre>"},{"location":"deployment/#using-the-deployed-model-edgeproduction","title":"Using the Deployed Model (Edge/Production)","text":"<p>The exported <code>.pt</code> file is self-contained. You do not need the <code>kladml</code> library installed on the target device, only <code>torch</code>.</p>"},{"location":"deployment/#python-edgeserver","title":"Python (Edge/Server)","text":"<pre><code>import torch\n\n# 1. Load Model\nmodel = torch.jit.load(\"model.pt\")\nmodel.eval()\n\n# 2. Extract embedded scalar stats (Zero external dependencies!)\nmean = float(model.metadata()[\"scaler_mean\"])\nscale = float(model.metadata()[\"scaler_scale\"])\n\n# 3. Inference\n# Input: [Batch, SeqLen, 1] (Raw values)\ninput_data = torch.randn(1, 60, 1) \n\n# Preprocess (Standard Scaling)\ninput_scaled = (input_data - mean) / scale\n\n# Forward Pass\n# Output shape depends on the model.\n# See specific architecture documentation for output details (e.g., gluformer/GLUFORMER_ARCHITECTURE.md).\noutputs = model(input_scaled)\n</code></pre>"},{"location":"deployment/#c-embedded","title":"C++ (Embedded)","text":"<p>Since it is a TorchScript module, it can be loaded in C++ using <code>libtorch</code>:</p> <pre><code>#include &lt;torch/script.h&gt;\n\nint main() {\n  torch::jit::script::Module module = torch::jit::load(\"model.pt\");\n  // ... inference logic ...\n}\n</code></pre>"},{"location":"deployment/#supported-architectures","title":"Supported Architectures","text":"<p>Each architecture may implement custom wrapping logic for deployment.  See the architecture-specific documentation for details on input shapes and output formats.</p> <ul> <li>Gluformer: See <code>src/kladml/architectures/gluformer/GLUFORMER_ARCHITECTURE.md</code></li> </ul>"},{"location":"getting_started/","title":"Getting Started","text":"<p>This guide will get you up and running with KladML in under 5 minutes.</p>"},{"location":"getting_started/#installation","title":"Installation","text":"<pre><code># Core library (lightweight, no UI)\npip install kladml\n\n# Full CLI with Terminal UI\npip install \"kladml[cli]\"\n</code></pre>"},{"location":"getting_started/#verify-installation","title":"Verify Installation","text":"<pre><code>kladml version\n# KladML version X.X.X\n</code></pre>"},{"location":"getting_started/#option-1-universal-quickstart","title":"Option 1: Universal Quickstart","text":"<p>Note: The <code>quickstart</code> command is currently under maintenance. Please use the interactive workflow below.</p>"},{"location":"getting_started/#option-2-interactive-tui-recommended","title":"Option 2: Interactive TUI (Recommended)","text":"<p>Launch the Terminal User Interface for a guided experience:</p> <pre><code>kladml ui\n</code></pre>"},{"location":"getting_started/#option-3-traditional-workflow","title":"Option 3: Traditional Workflow","text":""},{"location":"getting_started/#initialize-a-project","title":"Initialize a Project","text":"<pre><code>kladml init\n</code></pre> <p>This creates the standard directory structure:</p> <pre><code>data/\n\u251c\u2500\u2500 kladml.sqlite        # Local database\n\u251c\u2500\u2500 configs/             # YAML configurations\n\u251c\u2500\u2500 datasets/            # Your data\n\u2514\u2500\u2500 projects/            # Training results\n    \u2514\u2500\u2500 {project}/\n        \u2514\u2500\u2500 {run_id}/\n            \u251c\u2500\u2500 config.yaml\n            \u251c\u2500\u2500 checkpoints/\n            \u251c\u2500\u2500 exports/\n            \u2514\u2500\u2500 evaluations/\n</code></pre>"},{"location":"getting_started/#train-with-config","title":"Train with Config","text":"<pre><code>kladml train --config data/configs/my_experiment.yaml\n</code></pre> <p>Example config:</p> <pre><code>project: my-project\nexperiment: baseline_v1\n\ndataset: my_data/processed\narchitecture: TransformerAutoencoder\nparams:\n  d_model: 64\n  n_heads: 4\n\ntraining:\n  epochs: 50\n  batch_size: 128\n\nexport:\n  auto: true\n  format: onnx\n\nevaluation:\n  auto: true\n  evaluator: AnomalyEvaluator\n</code></pre>"},{"location":"getting_started/#evaluate-a-run","title":"Evaluate a Run","text":"<pre><code>kladml eval --run run_001 --evaluator AnomalyEvaluator --plots cdf,loglog\n</code></pre>"},{"location":"getting_started/#compare-runs","title":"Compare Runs","text":"<pre><code>kladml compare --runs run_001,run_002 --metric val_loss\n</code></pre>"},{"location":"getting_started/#hyperparameter-tuning","title":"Hyperparameter Tuning","text":"<p>Use Optuna integration for automated hyperparameter search:</p> <pre><code>kladml tune --config config.yaml --n-trials 50 --timeout 3600\n</code></pre>"},{"location":"getting_started/#create-custom-models","title":"Create Custom Models","text":"<pre><code>from kladml import BaseModel, MLTask\n\nclass MyModel(BaseModel):\n\n    @property\n    def ml_task(self):\n        return MLTask.CLASSIFICATION\n\n    def train(self, X_train, y_train=None, **kwargs):\n        # Your training logic\n        return {\"accuracy\": 0.95}\n\n    def predict(self, X, **kwargs):\n        return predictions\n\n    def evaluate(self, X_test, y_test=None, **kwargs):\n        return {\"accuracy\": 0.93, \"f1\": 0.91}\n\n    def save(self, path: str):\n        # Save model artifacts\n        pass\n\n    def load(self, path: str):\n        # Load model artifacts\n        pass\n</code></pre> <p>Register it:</p> <pre><code>kladml registry register --name MyModel --path my_model.py --type model\n</code></pre> <p>Then use it:</p> <pre><code>kladml train --config config.yaml  # config references \"MyModel\"\n</code></pre>"},{"location":"getting_started/#next-steps","title":"Next Steps","text":"<ul> <li>Core Concepts - Understand interfaces and architecture</li> <li>Architecture - Deep dive into model contracts</li> <li>Roadmap - Planned features</li> <li>CLI Reference - All available commands</li> </ul>"},{"location":"roadmap/","title":"Roadmap","text":"<p>What's coming in future versions of KladML.</p>"},{"location":"roadmap/#current-version-v05x","title":"Current Version: v0.5.x","text":""},{"location":"roadmap/#available-now","title":"\u2705 Available Now","text":"<ul> <li>ONNX Export - Export models to ONNX format for edge deployment</li> <li>TorchScript Export - Self-contained deployment artifacts</li> <li>Multiple Evaluators - Anomaly, Classification, Regression evaluation</li> <li>Plot Types - Histogram, CDF, Log-Log, Loss Curves</li> <li>Run Tracking - Automatic run ID generation and tracking</li> <li>Early Stopping - Configurable patience and minimum delta</li> <li>Registry System - Architecture and component registration</li> <li>Terminal UI (TUI) - Interactive terminal interface (<code>kladml ui</code>)</li> <li>CLI Commands - train, evaluate, data, project, family, experiment</li> </ul>"},{"location":"roadmap/#v06x-core-cli-enhancements","title":"v0.6.x - Core CLI Enhancements","text":"<p>Complete the core command-line workflow:</p> <ul> <li>[ ] Enhanced Training - <code>kladml train --config &lt;path&gt;</code> with better progress tracking</li> <li>[ ] Run Evaluation - <code>kladml evaluate --run &lt;run_id&gt; --evaluator &lt;name&gt;</code></li> <li>[ ] Model Export - <code>kladml export --run &lt;run_id&gt; --format &lt;onnx|torchscript&gt;</code></li> <li>[ ] Run Comparison - <code>kladml compare --runs run_001,run_002</code></li> <li>[ ] Component Listing - <code>kladml list &lt;runs|datasets|architectures&gt;</code></li> <li>[ ] Better Error Messages - Helpful suggestions when something goes wrong</li> <li>[ ] Progress Indicators - Real-time progress for long operations</li> </ul>"},{"location":"roadmap/#v07x-preprocessing-pipelines","title":"v0.7.x - Preprocessing Pipelines","text":"<p>Composable data preprocessing:</p> <ul> <li>[ ] YAML Pipeline Definition - Define preprocessing steps in config</li> <li>[ ] Component Chaining - Link preprocessors with schema validation</li> <li>[ ] CLI Command - <code>kladml data process --pipeline &lt;config&gt;</code></li> <li>[ ] Auto-split - Train/val/test splitting with reproducibility</li> </ul>"},{"location":"roadmap/#v08x-tui-improvements","title":"v0.8.x - TUI Improvements","text":"<p>Enhancements to the existing Terminal UI:</p> <ul> <li>[ ] Live Training Monitor - Real-time loss curves in terminal</li> <li>[ ] Inline Plots - View evaluation plots directly in TUI</li> <li>[ ] One-click Actions - Export, evaluate, compare from UI</li> <li>[ ] Improved Navigation - Better keyboard shortcuts</li> </ul>"},{"location":"roadmap/#v09x-smart-config-generator","title":"v0.9.x - Smart Config Generator","text":"<p>Intelligent configuration assistant:</p> <ul> <li>[ ] Data Analysis - Auto-detect data type (tabular, timeseries, image, text)</li> <li>[ ] Task Suggestion - Recommend task based on data characteristics</li> <li>[ ] Config Templates - Generate ready-to-use configuration files</li> <li>[ ] CLI Command:   <pre><code>kladml config generate --data my_data.csv\n# Output: configs/my_data_template.yaml\n</code></pre></li> </ul>"},{"location":"roadmap/#v010x-universal-quickstart-optional","title":"v0.10.x - Universal Quickstart (Optional)","text":"<p>One-command training for demos and onboarding:</p> <ul> <li>[ ] Quickstart Command - <code>kladml quickstart --data &lt;path&gt;</code></li> <li>[ ] Auto-workflow - Detect \u2192 Generate config \u2192 Train \u2192 Evaluate</li> <li>[ ] Pre-configured pipelines for common cases</li> </ul> <p>Note: This is a thin wrapper around existing commands, primarily for marketing and demos.</p>"},{"location":"roadmap/#v100-stable-release","title":"v1.0.0 - Stable Release","text":"<p>First stable release with:</p> <ul> <li>[ ] Comprehensive documentation</li> <li>[ ] Full test coverage</li> <li>[ ] API stability guarantees</li> <li>[ ] Migration guides from previous versions</li> </ul>"},{"location":"roadmap/#future-ideas","title":"Future Ideas","text":"<p>These are being considered but not yet planned:</p> Feature Description Hyperparameter Tuning Optuna integration for automated HPO Distributed Training Multi-GPU support Remote Execution Run on cloud infrastructure Model Versioning Track model versions with metadata Experiment Templates Reusable experiment configurations"},{"location":"roadmap/#contributing","title":"Contributing","text":"<p>Want to help shape the roadmap? </p> <ul> <li>\ud83d\udca1 Open a Feature Request</li> <li>\ud83d\udc1b Report a Bug</li> <li>\ud83e\udd1d Contribute Code</li> </ul>"},{"location":"roadmap/#changelog","title":"Changelog","text":"<p>See CHANGELOG.md for detailed version history.</p>"}]}